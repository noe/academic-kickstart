---
title: 'Notes on EMNLP 2018'
date: 2018-11-01
draft: false
---

I recently attended the
[Empirical Methods in Natural Language Processing (EMNLP)](http://emnlp2018.org/) conference.
Before the main conference, there are two days of co-located events. The two most
remarkable ones are the [Conference on Machine Translation (WMT)](http://www.statmt.org/wmt18/) and
the [SIGNLL Conference on Computational Natural Language Learning (CoNLL)](http://www.conll.org/2018).

[WMT](http://www.statmt.org/wmt18/) 

[CoNLL](http://www.conll.org/2018)

[BlackboxNLP](https://blackboxnlp.github.io/)

Tutorials

After the workshops


My personal view is that the research presented at EMNLP 2018, in general, complies too much
with the "empirical methods" part of the conference name: many papers and presentations are about
characterizing the behaviour of models and the surprising effects observed when they are subjected to
explorative experiments, but the analyses undergone to explain them are sometimes superficial or
are merely justified by intuition, and there are few conclusions that can be applied to contexts
other than those very specific experiments.
Although the [Blackbox NLP Workshop](https://blackboxnlp.github.io/) tried to shed some light on
the inner working of deep NLP models, I think the _black box nature_ of the currently
dominant models imposes a hard non-interpretability wall that prevents us from actually
understanding their behaviour completely, and hence we just can resort to characterizing
them under different conditions.
Like if we were trying to understand [Plato's cave](https://en.wikipedia.org/wiki/Allegory_of_the_Cave),
only that we ourselves are the ones who built the deep learning cave.
I hope that at some point we devise models with built-in interpretability where
we no longer need to trade interpretability for effectiveness.


If you want to know more about what happened at EMNLP 2018, I recommend
[searching for hashtag #emnlp2018 on twitter](https://twitter.com/search?q=%23emnlp2018&src=typd)
as there was plenty of live tweeting.
